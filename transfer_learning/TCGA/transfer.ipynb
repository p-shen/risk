{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating CI on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File genetech.batch_norm_genes.tsv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-880954d474f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"genetech.batch_norm_genes.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclinical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IMvigor210.clinical\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/Peter/Documents/GitHub/risk/models/all_immune_genes/checkpoint.0220.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pzs2/keras/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pzs2/keras/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pzs2/keras/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pzs2/keras/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pzs2/keras/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File genetech.batch_norm_genes.tsv does not exist"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"genetech.batch_norm_genes.tsv\", sep=\"\\t\")\n",
    "clinical = pd.read_csv(\"IMvigor210.clinical\", sep=\"\\t\")\n",
    "model_path = \"/Users/Peter/Documents/GitHub/risk/models/all_immune_genes/checkpoint.0220.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def negative_log_partial_likelihood(censor, risk):\n",
    "    \"\"\"Return the negative log-partial likelihood of the prediction\n",
    "    y_true contains the survival time\n",
    "    risk is the risk output from the neural network\n",
    "    censor is the vector of inputs that are censored\n",
    "    regularization is the regularization constant (not used currently in model)\n",
    "\n",
    "    Uses the Keras backend to perform calculations\n",
    "\n",
    "    Sorts the surv_time by sorted reverse time\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate negative log likelihood from estimated risk\n",
    "    epsilon = 0.001\n",
    "    hazard_ratio = K.exp(risk)\n",
    "\n",
    "    # cumsum on sorted surv time accounts for concordance\n",
    "    log_risk = K.log(tf.cumsum(hazard_ratio+epsilon))\n",
    "    uncensored_likelihood = risk - log_risk\n",
    "\n",
    "    # apply censor mask: 1 - dead, 0 - censor\n",
    "    censored_likelihood = uncensored_likelihood * censor\n",
    "    num_observed_events = K.sum(censor)\n",
    "    neg_likelihood = - K.sum(censored_likelihood) / \\\n",
    "        tf.cast(num_observed_events, tf.float32)\n",
    "    return neg_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              1076224   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,212,097\n",
      "Trainable params: 2,207,489\n",
      "Non-trainable params: 4,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "surv_model = load_model(model_path, custom_objects={\n",
    "                                        'negative_log_partial_likelihood': negative_log_partial_likelihood})\n",
    "surv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5247751719273497"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "\n",
    "def concordance_metric(survival_time, predicted_risk, censor):\n",
    "    # calculate the concordance index\n",
    "    epsilon = 0.001\n",
    "    partial_hazard = np.exp(-(predicted_risk+epsilon)).flatten()\n",
    "    censor = censor.astype(int)\n",
    "    ci = concordance_index(survival_time, partial_hazard, censor)\n",
    "    return ci\n",
    "\n",
    "predictions = surv_model.predict(data)\n",
    "concordance_metric(clinical[\"OS\"], predictions, clinical['Event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Cox Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clinical[['Response']].values\n",
    "index = ~np.isnan(labels).flatten()\n",
    "labels = labels[index,]\n",
    "data = data.values\n",
    "data = data[index,:]\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "VALIDATION_SPLIT = 0.8\n",
    "\n",
    "# indices = np.arange(tpm.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# # tpm = tpm[indices]\n",
    "# labels = surv_time[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:num_validation_samples]\n",
    "y_train = labels[:num_validation_samples]\n",
    "x_val = data[num_validation_samples:]\n",
    "y_val = labels[num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               269056    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 537,857\n",
      "Trainable params: 535,297\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/surv/lib/python3.6/site-packages/keras/engine/training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "surv_model = Sequential()\n",
    "surv_model = load_model(model_path, custom_objects={\n",
    "                                        'negative_log_partial_likelihood': negative_log_partial_likelihood})\n",
    "\n",
    "# taking out the last layer layers\n",
    "inp = surv_model.input\n",
    "surv_model.pop()\n",
    "surv_model.pop()\n",
    "surv_model.pop()\n",
    "\n",
    "surv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# to test with just linear cox regression\n",
    "cox_model = surv_model\n",
    "\n",
    "# freeze all the layers to test the weights\n",
    "for layer in cox_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "opt = Adam(lr=3e-2)\n",
    "\n",
    "loss_fn = negative_log_partial_likelihood\n",
    "cox_model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "cox_output = cox_model.predict(data)\n",
    "cox_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with Deep Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-37a3ed4964fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# from imblearn.over_sampling import SMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"genetech.batch_norm_genes.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclinical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IMvigor210.clinical\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "data = pd.read_csv(\"genetech.batch_norm_genes.tsv\", sep=\"\\t\")\n",
    "clinical = pd.read_csv(\"IMvigor210.clinical\", sep=\"\\t\")\n",
    "\n",
    "labels = clinical[['Response']].values\n",
    "index = ~np.isnan(labels).flatten()\n",
    "labels = labels[index,]\n",
    "data = data.values\n",
    "data = data[index,:]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.20, stratify=labels.flatten())\n",
    "\n",
    "# sm = SMOTE()\n",
    "# x_train_res, y_train_res = sm.fit_sample(x_train, y_train.ravel())\n",
    "# x_val_res, y_val_res = sm.fit_sample(x_val, y_val.ravel())\n",
    "# y_train_res_cat = np.append(y_train_res.reshape([-1,1]), np.abs(y_train_res - 1).reshape([-1,1]), axis=1)\n",
    "# y_val_res_cat = np.append(y_val_res.reshape([-1,1]), np.abs(y_val_res - 1).reshape([-1,1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              1076224   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "xfer_output (Dense)          (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,409,217\n",
      "Trainable params: 2,207,489\n",
      "Non-trainable params: 2,201,728\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/surv/lib/python3.6/site-packages/keras/engine/training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "surv_model = Sequential()\n",
    "surv_model = load_model(model_path, custom_objects={\n",
    "                                        'negative_log_partial_likelihood': negative_log_partial_likelihood})\n",
    "\n",
    "# taking out the last layer layers\n",
    "surv_model.pop()\n",
    "xfer_model = surv_model\n",
    "\n",
    "xfer_model.add(layers.Dense(1, activation=\"sigmoid\", name=\"xfer_output\"))\n",
    "\n",
    "# freeze all the layers before the output layer\n",
    "for layer in xfer_model.layers[0:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "xfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 368 samples, validate on 92 samples\n",
      "Epoch 1/30\n",
      "368/368 [==============================] - 10s 28ms/step - loss: 6031576.5870 - acc: 0.4918 - val_loss: 4271704.9783 - val_acc: 0.4783\n",
      "Epoch 2/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 6061449.4457 - acc: 0.5136 - val_loss: 4271705.0163 - val_acc: 0.4891\n",
      "Epoch 3/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 6015499.7609 - acc: 0.4728 - val_loss: 4271704.9783 - val_acc: 0.4674\n",
      "Epoch 4/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 6089169.9674 - acc: 0.5326 - val_loss: 4271705.0163 - val_acc: 0.5000\n",
      "Epoch 5/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 6002937.6957 - acc: 0.5136 - val_loss: 4271704.9783 - val_acc: 0.5000\n",
      "Epoch 6/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 6053548.4674 - acc: 0.4918 - val_loss: 4271704.9783 - val_acc: 0.4022\n",
      "Epoch 7/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 6074454.1848 - acc: 0.5082 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 8/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 6019745.1087 - acc: 0.4864 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 9/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 5967516.5000 - acc: 0.5408 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 10/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 5977481.6304 - acc: 0.5245 - val_loss: 4271704.9783 - val_acc: 0.3913\n",
      "Epoch 11/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 6028197.9783 - acc: 0.5217 - val_loss: 4271704.9783 - val_acc: 0.4565\n",
      "Epoch 12/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 6066261.5543 - acc: 0.5136 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 13/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 6039916.9348 - acc: 0.4755 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 14/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 6007002.9565 - acc: 0.5027 - val_loss: 4271704.9783 - val_acc: 0.3478\n",
      "Epoch 15/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 5944308.4130 - acc: 0.5163 - val_loss: 4271704.9783 - val_acc: 0.3913\n",
      "Epoch 16/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 5990731.0652 - acc: 0.5217 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 17/30\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 6016000.1957 - acc: 0.5299 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 18/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 5972025.8478 - acc: 0.5136 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 19/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 6092922.5000 - acc: 0.5163 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 20/30\n",
      "368/368 [==============================] - 1s 4ms/step - loss: 6014819.6739 - acc: 0.5163 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 21/30\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 6060224.2935 - acc: 0.5000 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 22/30\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 6018594.3261 - acc: 0.5217 - val_loss: 4271704.9783 - val_acc: 0.4891\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-14869da20a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           validation_data=(x_val_res, y_val_res))\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/surv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/envs/surv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/surv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/surv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/surv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(lr=3e-2)\n",
    "\n",
    "xfer_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "xfer_model.fit(x_train_res, y_train_res,\n",
    "          batch_size=64,\n",
    "          epochs=30,\n",
    "          validation_data=(x_val_res, y_val_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20991541],\n",
       "       [0.21272932],\n",
       "       [0.21062167],\n",
       "       [0.21154906],\n",
       "       [0.21007502],\n",
       "       [0.20977132],\n",
       "       [0.21046393],\n",
       "       [0.21228957],\n",
       "       [0.21004291],\n",
       "       [0.21030395],\n",
       "       [0.20979358],\n",
       "       [0.20966385],\n",
       "       [0.2102215 ],\n",
       "       [0.21104631],\n",
       "       [0.21001796],\n",
       "       [0.21006668],\n",
       "       [0.21272932],\n",
       "       [0.21000938],\n",
       "       [0.2108271 ],\n",
       "       [0.21001098],\n",
       "       [0.20981066],\n",
       "       [0.20979513],\n",
       "       [0.21161972],\n",
       "       [0.20965242],\n",
       "       [0.21039522],\n",
       "       [0.21272932],\n",
       "       [0.20981507],\n",
       "       [0.21048294],\n",
       "       [0.21017742],\n",
       "       [0.21062434],\n",
       "       [0.2100706 ],\n",
       "       [0.20941243],\n",
       "       [0.20964184],\n",
       "       [0.20964791],\n",
       "       [0.2104498 ],\n",
       "       [0.21036242],\n",
       "       [0.2094543 ],\n",
       "       [0.2096082 ],\n",
       "       [0.20993097],\n",
       "       [0.2098705 ],\n",
       "       [0.21017985],\n",
       "       [0.21002088],\n",
       "       [0.20998134],\n",
       "       [0.20961434],\n",
       "       [0.20950387],\n",
       "       [0.21272932],\n",
       "       [0.20996553],\n",
       "       [0.20972873],\n",
       "       [0.20958517],\n",
       "       [0.21094735],\n",
       "       [0.2100936 ],\n",
       "       [0.21028683],\n",
       "       [0.21014115],\n",
       "       [0.20967849],\n",
       "       [0.21074803],\n",
       "       [0.21041179],\n",
       "       [0.21001197],\n",
       "       [0.2104061 ],\n",
       "       [0.2101861 ],\n",
       "       [0.20996585],\n",
       "       [0.2098026 ],\n",
       "       [0.21022803],\n",
       "       [0.20962305],\n",
       "       [0.21012759],\n",
       "       [0.20954187],\n",
       "       [0.21130957],\n",
       "       [0.2100645 ],\n",
       "       [0.20969976],\n",
       "       [0.20964321],\n",
       "       [0.20979168],\n",
       "       [0.2097924 ],\n",
       "       [0.20997858],\n",
       "       [0.2096666 ],\n",
       "       [0.20938276],\n",
       "       [0.20967345],\n",
       "       [0.20969787],\n",
       "       [0.21037175],\n",
       "       [0.21019246],\n",
       "       [0.20981532],\n",
       "       [0.20952143],\n",
       "       [0.2098616 ],\n",
       "       [0.20963545],\n",
       "       [0.21040761],\n",
       "       [0.20956673],\n",
       "       [0.21026926],\n",
       "       [0.20990151],\n",
       "       [0.20987564],\n",
       "       [0.21012548],\n",
       "       [0.20981382],\n",
       "       [0.20944054],\n",
       "       [0.21049573],\n",
       "       [0.20950787],\n",
       "       [0.20989962],\n",
       "       [0.21021575],\n",
       "       [0.21029134],\n",
       "       [0.20991546],\n",
       "       [0.21272932],\n",
       "       [0.20997366],\n",
       "       [0.21190594],\n",
       "       [0.21051237],\n",
       "       [0.21057083],\n",
       "       [0.20958568],\n",
       "       [0.21047805],\n",
       "       [0.20955694],\n",
       "       [0.20947564],\n",
       "       [0.20948814],\n",
       "       [0.20975097],\n",
       "       [0.20986836],\n",
       "       [0.21113436],\n",
       "       [0.21000329],\n",
       "       [0.21155469],\n",
       "       [0.2098071 ],\n",
       "       [0.20958023],\n",
       "       [0.2113697 ],\n",
       "       [0.21272932],\n",
       "       [0.21044815],\n",
       "       [0.21010074],\n",
       "       [0.20974566],\n",
       "       [0.20991243],\n",
       "       [0.2108302 ],\n",
       "       [0.21046647],\n",
       "       [0.20964085],\n",
       "       [0.20955095],\n",
       "       [0.21159694],\n",
       "       [0.20971517],\n",
       "       [0.21001674],\n",
       "       [0.2098142 ],\n",
       "       [0.20976034],\n",
       "       [0.2104454 ],\n",
       "       [0.21154399],\n",
       "       [0.21182327],\n",
       "       [0.21805525],\n",
       "       [0.21000783],\n",
       "       [0.20954344],\n",
       "       [0.2107321 ],\n",
       "       [0.21029224],\n",
       "       [0.21039097],\n",
       "       [0.20967226],\n",
       "       [0.21007517],\n",
       "       [0.21006238],\n",
       "       [0.21041246],\n",
       "       [0.20955352],\n",
       "       [0.20960042],\n",
       "       [0.21041268],\n",
       "       [0.20999931],\n",
       "       [0.21023238],\n",
       "       [0.2102481 ],\n",
       "       [0.2122829 ],\n",
       "       [0.21009153],\n",
       "       [0.20970686],\n",
       "       [0.20976588],\n",
       "       [0.2103735 ],\n",
       "       [0.20983988],\n",
       "       [0.21028525],\n",
       "       [0.21025027],\n",
       "       [0.20968744],\n",
       "       [0.21059194],\n",
       "       [0.20981339],\n",
       "       [0.2112816 ],\n",
       "       [0.21023932],\n",
       "       [0.21028364],\n",
       "       [0.21030137],\n",
       "       [0.2111476 ],\n",
       "       [0.2096858 ],\n",
       "       [0.2094131 ],\n",
       "       [0.21051086],\n",
       "       [0.2102078 ],\n",
       "       [0.21011066],\n",
       "       [0.20994665],\n",
       "       [0.21005538],\n",
       "       [0.21029106],\n",
       "       [0.21055083],\n",
       "       [0.20954296],\n",
       "       [0.2104352 ],\n",
       "       [0.20993857],\n",
       "       [0.20985997],\n",
       "       [0.20973758],\n",
       "       [0.20971936],\n",
       "       [0.20981729],\n",
       "       [0.21016026],\n",
       "       [0.21167186],\n",
       "       [0.21007553],\n",
       "       [0.20984438],\n",
       "       [0.2101741 ],\n",
       "       [0.20983757],\n",
       "       [0.21036324],\n",
       "       [0.21064998],\n",
       "       [0.21005927],\n",
       "       [0.20980611],\n",
       "       [0.20984593],\n",
       "       [0.20961128],\n",
       "       [0.20977035],\n",
       "       [0.21025135],\n",
       "       [0.20975412],\n",
       "       [0.20968771],\n",
       "       [0.21000715],\n",
       "       [0.20961043],\n",
       "       [0.20982842],\n",
       "       [0.20964633],\n",
       "       [0.20981574],\n",
       "       [0.20960759],\n",
       "       [0.20992751],\n",
       "       [0.20932886],\n",
       "       [0.2096228 ],\n",
       "       [0.20985526],\n",
       "       [0.20999761],\n",
       "       [0.20944104],\n",
       "       [0.20965122],\n",
       "       [0.20990752],\n",
       "       [0.20982684],\n",
       "       [0.20964077],\n",
       "       [0.20983267],\n",
       "       [0.21015754],\n",
       "       [0.21003914],\n",
       "       [0.20984241],\n",
       "       [0.20983633],\n",
       "       [0.20950867],\n",
       "       [0.21008609],\n",
       "       [0.21147506],\n",
       "       [0.20981388],\n",
       "       [0.21033214],\n",
       "       [0.20966911],\n",
       "       [0.21062654],\n",
       "       [0.21089885],\n",
       "       [0.21012877],\n",
       "       [0.20931286],\n",
       "       [0.21026888],\n",
       "       [0.21148968],\n",
       "       [0.21046837],\n",
       "       [0.21002637],\n",
       "       [0.21035485],\n",
       "       [0.21164797],\n",
       "       [0.21003105],\n",
       "       [0.21024662],\n",
       "       [0.2103714 ],\n",
       "       [0.20993432],\n",
       "       [0.20997919],\n",
       "       [0.2096621 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xfer_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Top Genes from Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"tpm.xfer.X.txt\", sep=\"\\t\")\n",
    "labels = pd.read_csv(\"tpm.xfer.y.txt\", sep=\"\\t\")\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               269056    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "xfer_dense1 (Dense)          (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "xfer_batchnorm_1 (BatchNorma (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "output_dense (Dense)         (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 1,056,385\n",
      "Trainable params: 535,297\n",
      "Non-trainable params: 521,088\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/surv/lib/python3.6/site-packages/keras/engine/training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "\n",
    "surv_model = Sequential()\n",
    "surv_model = load_model(model_path, custom_objects={\n",
    "                                        'negative_log_partial_likelihood': negative_log_partial_likelihood})\n",
    "\n",
    "# taking out the last layer layers\n",
    "surv_model.pop()\n",
    "surv_model.pop()\n",
    "surv_model.pop()\n",
    "\n",
    "reg_model = surv_model\n",
    "reg_model.add(layers.Dense(64, activation='relu', name=\"xfer_dense1\"))\n",
    "reg_model.add(layers.BatchNormalization(name=\"xfer_batchnorm_1\"))\n",
    "reg_model.add(layers.Dense(14, activation=\"relu\", name=\"output_dense\"))\n",
    "\n",
    "# freeze all the layers before the output layer\n",
    "for layer in reg_model.layers[0:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "reg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (1050,) but got array with shape (945,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5fd41cb0b0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           validation_data=(x_val, y_val))\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/surv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/surv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/surv/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (1050,) but got array with shape (945,)"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.03)\n",
    "\n",
    "reg_model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "reg_model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting ICB response based on these outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.add(layers.Dense(1, activation=\"sigmoid\", name=\"reg_output\"))\n",
    "\n",
    "# freeze all the layers before the output layer\n",
    "for layer in reg_model.layers[0:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "opt = Adam(lr=0.03)\n",
    "\n",
    "reg_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"genetech.batch_norm_genes.tsv\", sep=\"\\t\")\n",
    "clinical = pd.read_csv(\"IMvigor210.clinical\", sep=\"\\t\")\n",
    "\n",
    "labels = clinical[['Response']].values\n",
    "index = ~np.isnan(labels).flatten()\n",
    "labels = labels[index,]\n",
    "data = data.values\n",
    "data = data[index,:]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.33, stratify=labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tSNE Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking out the last 2 layers\n",
    "from keras.models import Model\n",
    "inp = surv_model.input\n",
    "output = surv_model.layers[-3].output\n",
    "model = Model(inp, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"genetech.batch_norm_genes.tsv\", sep=\"\\t\")\n",
    "\n",
    "results = model.predict(data)\n",
    "idx = ~np.isnan(clinical[\"Response\"])\n",
    "# clinical = clinical.values\n",
    "clinical = clinical.loc[idx,]\n",
    "results = results[idx,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=10000)\n",
    "tsne_results = tsne.fit_transform(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_feature = clinical['Response']\n",
    "\n",
    "target_ids = range(int(min(clinical_feature)), int(max(clinical_feature))+1)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = 'r', 'g', 'b', 'c', 'm', 'y', 'k', 'w', 'orange', 'purple'\n",
    "for i, c in zip(target_ids, colors):\n",
    "    plt.scatter(tsne_results[clinical_feature == i, 0], tsne_results[clinical_feature == i, 1], c=c)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_feature = clinical['Best']\n",
    "\n",
    "target_ids = range(int(min(clinical_feature)), int(max(clinical_feature))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
