{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Immunotherapy Response based on RNA-Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data and gene pathways\n",
    "TCGA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tpm = pd.read_csv(\"data/tcga_sample/expression.tsv\", sep=\"\\t\")\n",
    "survival = pd.read_csv(\"data/tcga_sample/survival.tsv\", sep=\"\\t\", skiprows=1, header=None)\n",
    "meta = pd.read_csv(\"data/tcga_sample/metadata.tsv\", sep=\"\\t\", skiprows=1, header=None)\n",
    "cytokines = pd.read_csv(\"data/genes.cytokine_immune.txt\", skiprows=2, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the TPM values for cytokines pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use cytokine expression\n",
    "tpm = tpm.reindex(cytokines.iloc[:,0].unique(), axis='columns')\n",
    "tpm = tpm.dropna(axis=1)\n",
    "\n",
    "# perform quantile normalization\n",
    "# https://stackoverflow.com/questions/37935920/quantile-normalization-on-pandas-dataframe\n",
    "tpm /= np.max(np.abs(tpm),axis=0) # scale between [0,1]\n",
    "rank_mean = tpm.stack().groupby(tpm.rank(method='first').stack().astype(int)).mean()\n",
    "tpm = tpm.rank(method='min').stack().astype(int).map(rank_mean).unstack()\n",
    "\n",
    "# convert pandas df to np array\n",
    "tpm = tpm.values\n",
    "survival = survival.iloc[:,1:3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "VALIDATION_SPLIT = 0.8\n",
    "\n",
    "# indices = np.arange(tpm.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# # tpm = tpm[indices]\n",
    "# labels = surv_time[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * tpm.shape[0])\n",
    "\n",
    "x_train = tpm[:num_validation_samples]\n",
    "y_train = survival[:num_validation_samples]\n",
    "x_val = tpm[num_validation_samples:]\n",
    "y_val = survival[num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survival Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def negative_log_partial_likelihood_loss(regularization):\n",
    "    #Wrapper function for the negative logg partial likelihood loss function\n",
    "    \n",
    "    def loss(y_true, risk):\n",
    "        return negative_log_partial_likelihood(y_true, risk, regularization)\n",
    "    return loss\n",
    "\n",
    "def negative_log_partial_likelihood(censor, risk, regularization):\n",
    "    \"\"\"Return the negative log-partial likelihood of the prediction\n",
    "    y_true contains the survival time\n",
    "    risk is the risk output from the neural network\n",
    "    censor is the vector of inputs that are censored\n",
    "    regularization is the regularization constant (not used currently)\n",
    "    \n",
    "    Uses the Keras backend to perform calculations\n",
    "    \n",
    "    Sorts the surv_time by sorted reverse time\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate negative log likelihood from estimated risk\n",
    "    K.print_tensor(censor)\n",
    "    K.print_tensor(risk)\n",
    "    hazard_ratio = K.exp(risk)\n",
    "    log_risk = K.log(tf.cumsum(hazard_ratio)) # cumsum on sorted surv time accounts for concordance\n",
    "    uncensored_likelihood = risk - log_risk\n",
    "    censored_likelihood = uncensored_likelihood * censor\n",
    "    num_observed_events = K.sum(censor)\n",
    "    neg_likelihood = - K.sum(censored_likelihood) / tf.cast(num_observed_events, tf.float32)\n",
    "    return neg_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(123)\n",
    "# negative_log_partial_likelihood(y_train, np.random.rand(y_train.shape[0], 2), 0).eval(session=K.get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00770439, 0.00770439, 0.09777909, 0.08354589, 0.14483557,\n",
       "         0.03750752, 0.06533576, 0.09507118, 0.10876231, 0.13890046,\n",
       "         0.15091908, 0.12206171, 0.48187445, 0.00770439, 0.00770439,\n",
       "         0.00770439, 0.16835241, 0.11855542, 0.04477338, 0.04356357,\n",
       "         0.08782074, 0.08175386, 0.16017084, 0.08354589, 0.36083847,\n",
       "         0.10876231, 0.08577805, 0.05328115, 0.05555696, 0.05104396,\n",
       "         0.07452724],\n",
       "        [0.00770439, 0.10876231, 0.00770439, 0.05433715, 0.01549208,\n",
       "         0.06885928, 0.00770439, 0.03144983, 0.0427311 , 0.00770439,\n",
       "         0.05784024, 0.05937713, 0.00770439, 0.00770439, 0.00770439,\n",
       "         0.00770439, 0.03144983, 0.02375978, 0.06885928, 0.05104396,\n",
       "         0.06533576, 0.09256924, 0.05328115, 0.04726486, 0.02430823,\n",
       "         0.03998144, 0.06391589, 0.0357079 , 0.02287782, 0.04186489,\n",
       "         0.05937713],\n",
       "        [0.00770439, 0.00770439, 0.04644952, 0.0125152 , 0.06056726,\n",
       "         0.06533576, 0.09777909, 0.04186489, 0.03750752, 0.00770439,\n",
       "         0.01385125, 0.05784024, 0.08782074, 0.00770439, 0.00770439,\n",
       "         0.00770439, 0.02985164, 0.04556465, 0.0255335 , 0.04726486,\n",
       "         0.03300299, 0.00923611, 0.02430823, 0.07452724, 0.08354589,\n",
       "         0.03465731, 0.02611727, 0.02145167, 0.0502553 , 0.04477338,\n",
       "         0.03998144],\n",
       "        [0.13890046, 0.00770439, 0.00770439, 0.01908645, 0.13392274,\n",
       "         0.04644952, 0.0793616 , 0.06391589, 0.06885928, 0.11175108,\n",
       "         0.36083847, 0.06691886, 0.00770439, 0.00770439, 0.00770439,\n",
       "         0.00770439, 0.03878618, 0.01049853, 0.00770439, 0.0125152 ,\n",
       "         0.00923611, 0.08782074, 0.04073407, 0.0125152 , 0.07228801,\n",
       "         0.09256924, 0.01622714, 0.01795834, 0.03878618, 0.01108299,\n",
       "         0.12903708],\n",
       "        [0.12206171, 0.00770439, 0.08577805, 0.02192631, 0.02430823,\n",
       "         0.08577805, 0.00770439, 0.02430823, 0.04477338, 0.12903708,\n",
       "         0.05433715, 0.07715581, 0.00770439, 0.00770439, 0.00770439,\n",
       "         0.00770439, 0.0502553 , 0.04477338, 0.02082614, 0.05937713,\n",
       "         0.0427311 , 0.08577805, 0.00770439, 0.05104396, 0.03998144,\n",
       "         0.04477338, 0.07715581, 0.0275692 , 0.01385125, 0.02611727,\n",
       "         0.05433715]]), array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_iter(data, labels, batch_size, shuffle=True, isValidationSet=False):\n",
    "    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n",
    "\n",
    "    # Sorts the batches by survival time\n",
    "    def data_generator():\n",
    "        data_size = len(data)\n",
    "        while True:\n",
    "            # Sample from the dataset for each epoch\n",
    "            if shuffle:\n",
    "                shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "                shuffled_data = data[shuffle_indices]\n",
    "                shuffled_labels = labels[shuffle_indices]\n",
    "            else:\n",
    "                shuffled_data = data\n",
    "                shuffled_labels = labels\n",
    "\n",
    "            for batch_num in range(num_batches_per_epoch):\n",
    "                start_index = batch_num * batch_size\n",
    "                end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "                X, y = shuffled_data[start_index: end_index], shuffled_labels[start_index: end_index]\n",
    "                \n",
    "                # Sort X and y by survival time in each batch\n",
    "                idx = np.argsort(abs(y[:,0]))[::-1]\n",
    "                X = X[idx, :]\n",
    "                y = y[idx, 1].reshape(-1,1) # sort by survival time and take censored data\n",
    "\n",
    "                # reshape for matmul\n",
    "                y = y.reshape(-1,1) #reshape to [n, 1] for matmul\n",
    "                \n",
    "                yield X, y\n",
    "\n",
    "    return num_batches_per_epoch, data_generator()\n",
    "\n",
    "train_steps, train_batches = batch_iter(x_train, y_train, 5)\n",
    "next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 2.4179 - acc: 0.3115 - val_loss: 1.9757 - val_acc: 0.1500\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.3990 - acc: 0.3073 - val_loss: 1.9712 - val_acc: 0.1500\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.4287 - acc: 0.2969 - val_loss: 1.9718 - val_acc: 0.1500\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.3826 - acc: 0.2885 - val_loss: 1.9758 - val_acc: 0.1500\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.3460 - acc: 0.2896 - val_loss: 1.9824 - val_acc: 0.1500\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.3138 - acc: 0.2740 - val_loss: 1.9889 - val_acc: 0.1500\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.3371 - acc: 0.2531 - val_loss: 1.9965 - val_acc: 0.1500\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.3398 - acc: 0.2542 - val_loss: 2.0046 - val_acc: 0.1500\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2999 - acc: 0.2500 - val_loss: 2.0156 - val_acc: 0.1500\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.3230 - acc: 0.2500 - val_loss: 2.0301 - val_acc: 0.1500\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2885 - acc: 0.2073 - val_loss: 2.0455 - val_acc: 0.1500\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2845 - acc: 0.2302 - val_loss: 2.0629 - val_acc: 0.1500\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.3293 - acc: 0.2000 - val_loss: 2.0840 - val_acc: 0.1500\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2474 - acc: 0.1875 - val_loss: 2.1059 - val_acc: 0.1500\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2683 - acc: 0.1802 - val_loss: 2.1312 - val_acc: 0.1000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2353 - acc: 0.1927 - val_loss: 2.1579 - val_acc: 0.1000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2701 - acc: 0.1885 - val_loss: 2.1902 - val_acc: 0.1000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.2199 - acc: 0.2115 - val_loss: 2.2173 - val_acc: 0.1000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2637 - acc: 0.2271 - val_loss: 2.2394 - val_acc: 0.1000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.2253 - acc: 0.2615 - val_loss: 2.2729 - val_acc: 0.1000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.1960 - acc: 0.2385 - val_loss: 2.3017 - val_acc: 0.1000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.2104 - acc: 0.2844 - val_loss: 2.3281 - val_acc: 0.1000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.1978 - acc: 0.2271 - val_loss: 2.3633 - val_acc: 0.1500\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1369 - acc: 0.2229 - val_loss: 2.4024 - val_acc: 0.1500\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.2003 - acc: 0.2344 - val_loss: 2.4203 - val_acc: 0.1500\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1495 - acc: 0.1885 - val_loss: 2.4421 - val_acc: 0.1500\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0754 - acc: 0.1729 - val_loss: 2.4694 - val_acc: 0.1500\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.0816 - acc: 0.1458 - val_loss: 2.5046 - val_acc: 0.1500\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.1538 - acc: 0.1771 - val_loss: 2.5506 - val_acc: 0.1500\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1101 - acc: 0.1573 - val_loss: 2.5972 - val_acc: 0.2000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.1105 - acc: 0.1583 - val_loss: 2.6488 - val_acc: 0.1500\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0616 - acc: 0.1802 - val_loss: 2.6952 - val_acc: 0.1500\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0119 - acc: 0.1188 - val_loss: 2.7557 - val_acc: 0.1500\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0057 - acc: 0.1115 - val_loss: 2.8082 - val_acc: 0.1500\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0689 - acc: 0.1583 - val_loss: 2.8521 - val_acc: 0.1500\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0347 - acc: 0.1302 - val_loss: 2.8715 - val_acc: 0.1500\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.1037 - acc: 0.1854 - val_loss: 2.8795 - val_acc: 0.2000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0480 - acc: 0.2115 - val_loss: 2.8804 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.0488 - acc: 0.2156 - val_loss: 2.9257 - val_acc: 0.2000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9653 - acc: 0.1615 - val_loss: 2.9662 - val_acc: 0.2000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9587 - acc: 0.1771 - val_loss: 3.0293 - val_acc: 0.1500\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9248 - acc: 0.1313 - val_loss: 3.1059 - val_acc: 0.1500\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9392 - acc: 0.0927 - val_loss: 3.1652 - val_acc: 0.1500\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8945 - acc: 0.0927 - val_loss: 3.1971 - val_acc: 0.2000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9369 - acc: 0.0885 - val_loss: 3.2119 - val_acc: 0.2000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8841 - acc: 0.1271 - val_loss: 3.2419 - val_acc: 0.2000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.9481 - acc: 0.1260 - val_loss: 3.2418 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9726 - acc: 0.1698 - val_loss: 3.2217 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0978 - acc: 0.1958 - val_loss: 3.1983 - val_acc: 0.2000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.9746 - acc: 0.1469 - val_loss: 3.1741 - val_acc: 0.2000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7906 - acc: 0.1542 - val_loss: 3.2085 - val_acc: 0.1500\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8709 - acc: 0.1698 - val_loss: 3.2379 - val_acc: 0.1500\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8952 - acc: 0.1344 - val_loss: 3.2567 - val_acc: 0.1000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8390 - acc: 0.1698 - val_loss: 3.2629 - val_acc: 0.1000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.7807 - acc: 0.1302 - val_loss: 3.2780 - val_acc: 0.1000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8160 - acc: 0.1000 - val_loss: 3.2939 - val_acc: 0.1000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8589 - acc: 0.1385 - val_loss: 3.3284 - val_acc: 0.1000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.7482 - acc: 0.0927 - val_loss: 3.3686 - val_acc: 0.1500\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7464 - acc: 0.1385 - val_loss: 3.4139 - val_acc: 0.1500\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8118 - acc: 0.1500 - val_loss: 3.4637 - val_acc: 0.1500\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.8897 - acc: 0.1469 - val_loss: 3.5168 - val_acc: 0.1500\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.7602 - acc: 0.1115 - val_loss: 3.5121 - val_acc: 0.1500\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6894 - acc: 0.1344 - val_loss: 3.5380 - val_acc: 0.1500\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.7116 - acc: 0.1229 - val_loss: 3.6129 - val_acc: 0.1500\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6417 - acc: 0.1646 - val_loss: 3.7152 - val_acc: 0.1500\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.7003 - acc: 0.1500 - val_loss: 3.7575 - val_acc: 0.2500\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6893 - acc: 0.1688 - val_loss: 3.7986 - val_acc: 0.2500\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.7287 - acc: 0.1573 - val_loss: 3.8228 - val_acc: 0.2500\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6384 - acc: 0.2000 - val_loss: 3.9112 - val_acc: 0.2500\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.6830 - acc: 0.1844 - val_loss: 3.9947 - val_acc: 0.2000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6102 - acc: 0.1573 - val_loss: 4.0362 - val_acc: 0.1500\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.7279 - acc: 0.1896 - val_loss: 3.9781 - val_acc: 0.1000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5999 - acc: 0.1844 - val_loss: 3.8305 - val_acc: 0.2000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5643 - acc: 0.1531 - val_loss: 3.7419 - val_acc: 0.2000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.6032 - acc: 0.2083 - val_loss: 3.7961 - val_acc: 0.2000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.6043 - acc: 0.2344 - val_loss: 3.9569 - val_acc: 0.2000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.6227 - acc: 0.1240 - val_loss: 4.1540 - val_acc: 0.2500\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.5601 - acc: 0.1542 - val_loss: 4.3277 - val_acc: 0.2500\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.6120 - acc: 0.0885 - val_loss: 4.3840 - val_acc: 0.2000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5416 - acc: 0.0958 - val_loss: 4.3236 - val_acc: 0.1000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5648 - acc: 0.0927 - val_loss: 4.2447 - val_acc: 0.2000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5085 - acc: 0.1656 - val_loss: 4.1458 - val_acc: 0.2000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4967 - acc: 0.1583 - val_loss: 4.1301 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5916 - acc: 0.2240 - val_loss: 4.1691 - val_acc: 0.1500\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4711 - acc: 0.1583 - val_loss: 4.2780 - val_acc: 0.1500\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5267 - acc: 0.1646 - val_loss: 4.4218 - val_acc: 0.1500\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4898 - acc: 0.1844 - val_loss: 4.5509 - val_acc: 0.1000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3804 - acc: 0.1000 - val_loss: 4.6326 - val_acc: 0.1500\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4191 - acc: 0.1073 - val_loss: 4.6513 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.5017 - acc: 0.1385 - val_loss: 4.6689 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3963 - acc: 0.1531 - val_loss: 4.7327 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.4415 - acc: 0.1500 - val_loss: 4.8269 - val_acc: 0.1500\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3677 - acc: 0.1198 - val_loss: 4.8360 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.4807 - acc: 0.1198 - val_loss: 4.7709 - val_acc: 0.2000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3227 - acc: 0.1156 - val_loss: 4.6996 - val_acc: 0.2000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3581 - acc: 0.1844 - val_loss: 4.7898 - val_acc: 0.2000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.3760 - acc: 0.1302 - val_loss: 4.9833 - val_acc: 0.1500\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.3168 - acc: 0.0958 - val_loss: 5.1530 - val_acc: 0.1000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2798 - acc: 0.1385 - val_loss: 5.3349 - val_acc: 0.1000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1400 - acc: 0.1302 - val_loss: 5.4969 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=x_train.shape[1], name=\"input\"))\n",
    "model.add(Dense(64, activation='relu', name=\"dense_1\"))\n",
    "model.add(Dropout(0.25, name=\"dropout_1\"))\n",
    "model.add(Dense(64, activation='relu', name=\"dense_2\"))\n",
    "model.add(Dense(1, activation='linear', name=\"output\"))\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "\n",
    "model_loss = negative_log_partial_likelihood_loss(0)\n",
    "\n",
    "model.compile(optimizer=opt, loss=model_loss, metrics=['accuracy']) # Accuracy is meaningless in this case, only look at loss\n",
    "\n",
    "train_steps, train_batches = batch_iter(x_train, y_train, BATCH_SIZE)\n",
    "valid_steps, valid_batches = batch_iter(x_val, y_val, BATCH_SIZE)\n",
    "history = model.fit_generator(train_batches, train_steps, epochs=100, validation_data=valid_batches, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.8087196 ],\n",
       "       [ -3.0801105 ],\n",
       "       [  0.6488666 ],\n",
       "       [ -2.4911418 ],\n",
       "       [ -4.5405602 ],\n",
       "       [ -0.5468623 ],\n",
       "       [ -1.0630792 ],\n",
       "       [ -0.38022354],\n",
       "       [  0.93381953],\n",
       "       [-21.032387  ],\n",
       "       [  0.31497198],\n",
       "       [ -3.0022564 ],\n",
       "       [ -5.1117077 ],\n",
       "       [ -9.084351  ],\n",
       "       [ -9.5970545 ],\n",
       "       [ -4.281399  ],\n",
       "       [ -0.6425    ],\n",
       "       [ -0.6677754 ],\n",
       "       [ -4.6419926 ],\n",
       "       [  0.5921529 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_val)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6482758620689655"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "\n",
    "predictions_time = np.exp(predictions)\n",
    "concordance_index(y_val[:,0], predictions_time, y_val[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0012704e-03],\n",
       "       [4.5954175e-02],\n",
       "       [1.9133710e+00],\n",
       "       [8.2815357e-02],\n",
       "       [1.0667428e-02],\n",
       "       [5.7876295e-01],\n",
       "       [3.4539062e-01],\n",
       "       [6.8370855e-01],\n",
       "       [2.5442083e+00],\n",
       "       [7.3409195e-10],\n",
       "       [1.3702209e+00],\n",
       "       [4.9674857e-02],\n",
       "       [6.0257842e-03],\n",
       "       [1.1342706e-04],\n",
       "       [6.7928529e-05],\n",
       "       [1.3823313e-02],\n",
       "       [5.2597582e-01],\n",
       "       [5.1284820e-01],\n",
       "       [9.6384734e-03],\n",
       "       [1.8078763e+00]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 158,  247,   56,  284,   77,   65,  955,  273,  214,  271, 3617,\n",
       "       3056,  218,  178,  202,   55,  322,  237, 3767, 2292])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
